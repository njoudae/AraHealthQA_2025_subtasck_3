{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C39ZOTe1qS2"
      },
      "source": [
        "#  MentalQA Dataset Description\n",
        "\n",
        "The full dataset consists of **500 annotated samples**. For the purpose of this shared task, we are using only the **training and development set**:\n",
        "\n",
        "- **Train+Dev Set**: 350 samples  \n",
        "- **Test Set**: 150 samples (withheld for evaluation purposes)\n",
        "\n",
        "---\n",
        "\n",
        "###  Dataset File: `MentalQA_500_data.csv` (tab-separated)\n",
        "\n",
        "This dataset was recently accepted in the *IEEE ACCESS* journal.  \n",
        "It contains **four columns** as follows:\n",
        "\n",
        "1. **Question**  \n",
        "2. **Answer**  \n",
        "3. **Question Types** (`final_QT`)  \n",
        "4. **Answer Strategies** (`final_AS`)\n",
        "\n",
        "---\n",
        "\n",
        "###  Question Type Labels (`final_QT`)\n",
        "\n",
        "| Label | Name                       |Description |\n",
        "|----------|----------------------------|----------------\n",
        "| A        | **Diagnosis**              | Questions about clinical findings, tests, disease criteria, and manifestations. |\n",
        "| B        | **Treatment**              | Questions about therapies, drug use, side effects, and contraindications. |\n",
        "| C        | **Anatomy and Physiology** | Basic medical knowledge (e.g., tissues, organs, metabolism). |\n",
        "| D        | **Epidemiology**           | Disease progression, prognosis, etiology, and risk factors. |\n",
        "| E        | **Healthy Lifestyle**      | Diet, exercise, mood, and lifestyle factors affecting mental health. |\n",
        "| F        | **Provider Choices**       | Recommendations for doctors, hospitals, or medical departments. |\n",
        "| Z        | **Other**                  | General or uncategorized questions. |\n",
        "\n",
        "---\n",
        "\n",
        "###  Answer Strategy Labels (`final_AS`)\n",
        "\n",
        "| Label   | Name              | Description |\n",
        "|---------|-----------|-------------|\n",
        "| 1       | **Information**    | Provides factual data, explanations, or resources. |\n",
        "| 2       |  **Direct Guidance**| Offers suggestions, instructions, or behavioral advice. |\n",
        "| 3       | **Emotional Support** | Gives reassurance, empathy, or emotional encouragement. |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "GitHub: https://github.com/hasanhuz/MentalQA/tree/main\n",
        "\n",
        "Paper: https://arxiv.org/abs/2405.12619"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jnNX87LGz_Wc"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install bert-score\n",
        "!pip install -U langchain langchain-community\n",
        "!pip install -U langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P91jTk812V0R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eamMs9_52ZzI"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_colwidth\", None, \"display.max_rows\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnCSAkcl2cZl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/Train_Dev.tsv', sep='\\t')\n",
        "data.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocqU1VES26NT"
      },
      "source": [
        "### Start Cleaning Dataset\n",
        "##  Data Preprocessing and Cleaning Overview\n",
        "\n",
        "Before performing any analysis or model evaluation, it is crucial to clean and normalize the dataset to ensure consistency and quality.\n",
        "\n",
        "This section outlines the preprocessing steps applied to the MentalQA Arabic dataset.\n",
        "\n",
        "---\n",
        "\n",
        "###  Cleaning Steps Applied:\n",
        "\n",
        "1. **Displayed full text columns** – Enabled full visibility of long question/answer text using `pd.set_option(\"display.max_colwidth\", None)`.\n",
        "2. **Email Removal** – Removed any embedded email addresses using regular expressions.\n",
        "3. **Separation Rules** – Inserted spaces between:\n",
        "   - Arabic letters and numbers (e.g., \"دواء20\" → \"دواء 20\")\n",
        "   - Arabic and English terms (e.g., \"علاجmg\" → \"علاج mg\")\n",
        "   - Numbers and English words (e.g., \"mg75\" → \"mg 75\")\n",
        "4. **Punctuation Cleanup** – Removed all punctuation marks except the Arabic question mark \"؟\".\n",
        "5. **Arabic Letter Normalization** – Standardized variations of alef (ا), ta marbuta (ه), and others.\n",
        "6. **Numeric Normalization** – Converted Arabic-Indic numerals (٠١٢...) to Western digits (012...).\n",
        "7. **Repetition Reduction** – Compressed elongated words (e.g., \"رااااائع\" → \"رائع\").\n",
        "8. **Question Mark Spacing** – Ensured space before and after \"؟\" to avoid it sticking to adjacent words.\n",
        "9. **Custom Corrections** – Applied multiple custom dictionaries to fix common spelling errors, typos, and fused terms (e.g., \"ماا\" → \"ما\", \"بلنتحار\" → \"بالانتحار\").\n",
        "\n",
        "---\n",
        "\n",
        "###  Word-Level Error Detection via Frequency Analysis\n",
        "\n",
        "To further enhance text quality, we analyzed both the cleaned questions and answers at the word level:\n",
        "\n",
        "- Combined all tokens from `question_clean_1` and `answer_clean_1`.\n",
        "- Used `collections.Counter` to calculate word frequencies.\n",
        "- Created a sorted DataFrame to highlight rare and suspicious words.\n",
        "- Manually reviewed low-frequency words to detect:\n",
        "  - Typos (e.g., \"هاذا\", \"معايا\", \"مفارقهمتصل\")\n",
        "  - Word merges and informal language\n",
        "- Built custom correction dictionaries based on the findings to normalize the vocabulary.\n",
        "\n",
        "This iterative refinement helped reduce vocabulary noise and improve input quality for downstream modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4XYMWRZ24oA"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUh5IcMC3FNr"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y8FB5CT33HQO"
      },
      "outputs": [],
      "source": [
        "df = data[['question', 'answer']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycO54aKj3PRJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_arabic_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    # 0. Normalize numbers\n",
        "    text = text.translate(str.maketrans(\"٠١٢٣٤٥٦٧٨٩\", \"0123456789\"))\n",
        "\n",
        "    # 1. Remove Email (واستبداله بمسافة)\n",
        "    text = re.sub(r'\\S*@\\S+', ' ', text)\n",
        "\n",
        "    # 2. Make Distance between Arabic and Numbers/English\n",
        "    text = re.sub(r'([ء-ي])(\\d+)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'(\\d+)([ء-ي])', r'\\1 \\2', text)\n",
        "    text = re.sub(r'([ء-ي])([a-zA-Z]+)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'([a-zA-Z]+)([ء-ي])', r'\\1 \\2', text)\n",
        "    text = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', text)\n",
        "    text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', text)\n",
        "\n",
        "    # 3. Remove repeated characters (مثلاً: كييييف → كيف)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
        "\n",
        "    # 4. Normalize Arabic letters\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    text = re.sub(r'گ', 'ك', text)\n",
        "\n",
        "    # 5. Remove punctuation (except ؟) مع استبدالها بمسافة\n",
        "    text = re.sub(r'[^\\w\\s؟]', ' ', text)\n",
        "\n",
        "    # 6. Ensure space before and after question mark\n",
        "    text = re.sub(r'\\s*؟\\s*', ' ؟ ', text)\n",
        "\n",
        "    # 7. Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "df[\"question_clean_1\"] = df[\"question\"].apply(clean_arabic_text)\n",
        "df[\"answer_clean_1\"] = df[\"answer\"].apply(clean_arabic_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KrrDIsH_3aqn"
      },
      "outputs": [],
      "source": [
        "all_text = ' '.join(df['question_clean_1'].astype(str))\n",
        "words = all_text.split()\n",
        "word_freq = Counter(words)\n",
        "freq_df = pd.DataFrame(word_freq.items(), columns=['word', 'count']).sort_values(by='count', ascending=True)\n",
        "freq_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rItI52T43dwm"
      },
      "outputs": [],
      "source": [
        "def apply_custom_corrections(text):\n",
        "    corrections = {\n",
        "        \"قي\": \"في\",\n",
        "        \"انااذكر\": \"أنا أذكر\",\n",
        "        \"ماا\": \"ما\",\n",
        "        \"عليكماعاني\": \"عليكم اعاني\",\n",
        "        \"هده\": \"هذه\",\n",
        "        \"للاكتئا\": \"للاكتئاب\",\n",
        "        \"بلسوء\": \"ب السوء\",\n",
        "        \"ءاذي\": \"الذي\",\n",
        "        \"ماكدر\": \"ما اقدر\",\n",
        "        \"معايا\": \"معي\",\n",
        "        \"حتا\": \"حتى\",\n",
        "        \"انوا\": \"أنه\",\n",
        "        \"اخري\": \"أخرى\",\n",
        "        \"بلنتحار\": \"ب الانتحار\",\n",
        "        \"بلاحباط\": \"ب الإحباط\",\n",
        "        \"منهاا\": \"منها\",\n",
        "        \"ابغا\": \"أريد\",\n",
        "        \"طمانتني\": \"طمنتني\",\n",
        "        \"وواحبها\": \"واحبها\",\n",
        "        \"مفعولخ\": \"مفعوله\",\n",
        "\n",
        "    }\n",
        "\n",
        "    for wrong, right in corrections.items():\n",
        "        text = text.replace(wrong, right)\n",
        "    return text\n",
        "\n",
        "df[\"question_clean_2\"] = df[\"question_clean_1\"].apply(apply_custom_corrections)\n",
        "#df[\"answer_clean_2\"] = df[\"answer_clean_1\"].apply(clean_arabic_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m4utnIb33hzO"
      },
      "outputs": [],
      "source": [
        "all_text_ = ' '.join(df['answer_clean_1'].astype(str))\n",
        "words_ = all_text_.split()\n",
        "word_freq_ = Counter(words_)\n",
        "freq_df_ = pd.DataFrame(word_freq_.items(), columns=['word', 'count']).sort_values(by='count', ascending=True)\n",
        "freq_df_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raOH0zW53jPe"
      },
      "outputs": [],
      "source": [
        "def apply_answer_corrections(text):\n",
        "    corrections = {\n",
        "        \"النفسيوربما\": \"النفسي وربما\",\n",
        "        \"العقاقيرويستحسن\": \"العقاقير ويستحسن\",\n",
        "        \"وضروريوايذاء\": \"و ضروري و إيذاء\",\n",
        "        \"والجرعهليقدرها\": \"و الجرعة ليقدرها\",\n",
        "        \"تسوءوربما\": \"تسوء وربما\",\n",
        "        \"تغييراو\": \"تغيير أو\",\n",
        "        \"ابق\": \"أبقى\",\n",
        "        \"الادويهنحتاج\": \"الأدوية نحتاج\",\n",
        "        \"الاعتماديهالاعتماد\": \"الاعتمادية الاعتماد\",\n",
        "        \"الحلتدريجيا\": \"الحل تدريجا\",\n",
        "        \"مفارقهالتعلق\": \"مفارقة التعلق\",\n",
        "        \"خطيرهلانها\": \"خطيرة لأنها\",\n",
        "        \"نفسيالافكاراالانتحاريه\": \"نفسي الأفكار الانتحارية\",\n",
        "        \"الخضارقللي\": \"الخضار قللي\",\n",
        "        \"غلى\": \"على\",\n",
        "        \"الجتماعي\": \"الاجتماعي\",\n",
        "        \"لكليهماونتوقف\": \"لكليهما و نتوقف\",\n",
        "        \"وانواعهاولوم\": \"و أنواعها و لوم\",\n",
        "        \"الناسنحتاج\": \"الناس نحتاج\",\n",
        "        \"المراءه\": \"المراة\",\n",
        "        \"هاذا\": \"هذا\",\n",
        "        \"المسسبه\": \"المسببه\",\n",
        "        \"اى\": \"اي\",\n",
        "        \"عضوى\": \"عضوي\",\n",
        "        \"النفسانيالافكار\": \"النفساني الأفكار\",\n",
        "        \"هدا\": \"هذا\",\n",
        "        \"اسرغ\": \"اسرع\",\n",
        "        \"والاسترخاءوهذا\": \"و الاسترخاء و هذا\",\n",
        "        \"الاخرفتصل\": \"الاخر فتصل\",\n",
        "        \"الاخروعندما\": \"الاخر و عندما\",\n",
        "        \"دواءي\": \"دوائي\",\n",
        "        \"مشهورهاسمها\": \"مشهور اسمه\"\n",
        "    }\n",
        "\n",
        "    for wrong, right in corrections.items():\n",
        "        text = text.replace(wrong, right)\n",
        "    return text\n",
        "\n",
        "df[\"answer_clean_2\"] = df[\"answer_clean_1\"].apply(apply_answer_corrections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Mo4LucI3qrt"
      },
      "outputs": [],
      "source": [
        "# Cleaning Columns\n",
        "df[['question_clean_2', 'answer_clean_2']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpF3u6j56gMQ"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY=\"gsk_....\"\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "\n",
        "chat = ChatGroq(\n",
        "    groq_api_key=GROQ_API_KEY,\n",
        "    model_name=\"llama3-70b-8192\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWRKGewi8Qkz"
      },
      "outputs": [],
      "source": [
        "def build_zero_shot_prompt(question):\n",
        "    return f\"أجب على السؤال التالي باحترافية وباللغة العربية:\\n\\nالسؤال: {question}\\n\\nالإجابة:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D9yjjek8SKn"
      },
      "outputs": [],
      "source": [
        "def generate_llama_answer(question):\n",
        "    prompt = build_zero_shot_prompt(question)\n",
        "    response = chat.invoke([\n",
        "        HumanMessage(content=prompt)\n",
        "    ])\n",
        "    return response.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVe7W9r48T4D"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_zero_shot_answer'] = sample_df['question_clean_2'].apply(generate_llama_answer)\n",
        "sample_df.to_csv(\"llama3_zero_shot_generated_answers.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYYziLpX8Wbs"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_zero_shot_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_f1'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama3_zero_shot_generated_answers.csv\", index=False)\n",
        "print(f\"✅ Average BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUkQD8Tt4CTL"
      },
      "outputs": [],
      "source": [
        "example_1 = {\n",
        "    \"question\": \"بقالي اكتر من اسبوعين مش بنام ولا باكل و لو نمت ساعه واحده في اليوم افضل صاحيه 3 ايام و بحلم بكابوس بيتكرر علي طول اني باذى نفسي لدرجه اني فكرت في كده\t\",\n",
        "    \"answer\": \"أنتي بحاجه لزيارة طبيب نفسي للتقيم اخذ السيره المرضيه بشكل ادق ولمعرفة تفاصيل اخرى مهمه في التشخيص لا تترددي في الاستشاره لان علامات المرض النفسي الحاد بدات تظهر بقله الحاجه للنوم تمنياتي بالشفاء العاجل\t\"\n",
        "}\n",
        "\n",
        "example_2 = {\n",
        "    \"question\": \"تمنعني ظروف ما اقدر اروح دكتور اخصائي ولا اشرح حالتي كدامه صرت افكر بالانتحار بسبب هاي الحاله شي مخيف أشد أنواع العذاب لدرجه الموت أهون الموت أهون\t\",\n",
        "    \"answer\": \"السلام عليكم علاج الادمان محتاج طبيب وادوية والاهم يكون عندك اراده قويه للتخلص من هذه السموم وعلى قدر عزيمتك هيكون التوفيق لنجاح العلاج ساعد نفسك\t\"\n",
        "}\n",
        "\n",
        "example_3 = {\n",
        "    \"question\": \"اعاني من الخوف وتنبؤات من كلام اهلي وبصمتهم انهم يبون يقتلوني بدون سبب والي محرضهم ابوي\",\n",
        "    \"answer\": \"التقلبات المزاجيه في سنك المبكره كثيره ومن المفيد مراجعه طبيب للتشخيص الدقيق\t\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l13L-X824EEs"
      },
      "outputs": [],
      "source": [
        "def build_fewshot_prompt(new_question):\n",
        "    prompt = f\"\"\"\n",
        "أجب على الأسئلة التالية باحترافية وباللغة العربية:\n",
        "\n",
        "س: {example_1['question']}\n",
        "ج: {example_1['answer']}\n",
        "\n",
        "س: {example_2['question']}\n",
        "ج: {example_2['answer']}\n",
        "\n",
        "س: {example_3['question']}\n",
        "ج: {example_3['answer']}\n",
        "\n",
        "س: {new_question}\n",
        "ج:\"\"\"\n",
        "    return prompt.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYNwU7d_4GHp"
      },
      "outputs": [],
      "source": [
        "def generate_llama_answer(question):\n",
        "    prompt = build_fewshot_prompt(question)\n",
        "    response = chat.invoke([\n",
        "        HumanMessage(content=prompt)\n",
        "    ])\n",
        "    return response.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXCZtO99dSa"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_few_shot_answer'] = sample_df['question_clean_2'].apply(generate_llama_answer)\n",
        "sample_df.to_csv(\"llama_few_shot_answer.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq9BFx8Y9k4j"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_few_shot_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_f1'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama_few_shot_answer.csv\", index=False)\n",
        "print(f\"✅ Average BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SNdw4NJ-Wv1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_fewshot_sc_answer(question, n=10): # I traied 5 answers then 10 anwsers but the F1 is same\n",
        "    answers = []\n",
        "    for _ in range(n):\n",
        "        prompt = build_fewshot_prompt(question)\n",
        "        response = chat.invoke(prompt, temperature=0.1)\n",
        "        answer = response.content.strip()\n",
        "        answers.append(answer)\n",
        "\n",
        "    most_common = Counter(answers).most_common(1)[0][0]\n",
        "    return most_common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCsj-vaa-Z9H"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_fewshot_sc_answer'] = sample_df['question_clean_2'].apply(generate_fewshot_sc_answer)\n",
        "sample_df.to_csv(\"llama_fewshot_sc_answer.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81YVC7ke-gpF"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_fewshot_sc_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_f1'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama_fewshot_sc_answer.csv\", index=False)\n",
        "print(f\"✅ Average BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzroTRlI_NEy"
      },
      "outputs": [],
      "source": [
        "def generate_multiple_llama_answers(question, n=5):\n",
        "    answers = []\n",
        "    for _ in range(n):\n",
        "        prompt = build_fewshot_prompt(question)\n",
        "        response = chat.invoke(prompt, temperature=0.1)\n",
        "        answers.append(response.content.strip())\n",
        "    return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5AnUNbg_QgH"
      },
      "outputs": [],
      "source": [
        "def build_refinement_prompt(question, answers):\n",
        "    joined_answers = \"\\n\\n\".join(\n",
        "    [f\"Answer {i+1}: {ans}\" for i, ans in enumerate(answers)]\n",
        "    )\n",
        "\n",
        "    return f\"\"\"Question: {question}\n",
        "\n",
        "    These are different answers to the same question:\n",
        "\n",
        "    {joined_answers}\n",
        "\n",
        "    Based on the previous answers, write an improved and ideal answer, taking into account accuracy and clarity:\n",
        "\n",
        "Final answer:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf8GIa5F_WhR"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_er_answer'] = sample_df['question_clean_2'].apply(\n",
        "    lambda q: build_refinement_prompt(q, generate_multiple_llama_answers(q, n=5))\n",
        ")\n",
        "sample_df.to_csv(\"llama_er_answer.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5SaV2MN_bgB"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_er_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_er_answer'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama_er_answer.csv\", index=False)\n",
        "print(f\"✅ Average BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaPz_8s1py7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFNl6UQ0BB5V"
      },
      "outputs": [],
      "source": [
        "example_1 = {\n",
        "    \"question\": \"بقالي اكتر من اسبوعين مش بنام ولا باكل و لو نمت ساعه واحده في اليوم افضل صاحيه 3 ايام و بحلم بكابوس بيتكرر علي طول اني باذى نفسي لدرجه اني فكرت في كده\t\",\n",
        "    \"answer\": \"أنتي بحاجه لزيارة طبيب نفسي للتقيم اخذ السيره المرضيه بشكل ادق ولمعرفة تفاصيل اخرى مهمه في التشخيص لا تترددي في الاستشاره لان علامات المرض النفسي الحاد بدات تظهر بقله الحاجه للنوم تمنياتي بالشفاء العاجل\t\"\n",
        "}\n",
        "\n",
        "example_2 = {\n",
        "    \"question\": \"تمنعني ظروف ما اقدر اروح دكتور اخصائي ولا اشرح حالتي كدامه صرت افكر بالانتحار بسبب هاي الحاله شي مخيف أشد أنواع العذاب لدرجه الموت أهون الموت أهون\t\",\n",
        "    \"answer\": \"السلام عليكم علاج الادمان محتاج طبيب وادوية والاهم يكون عندك اراده قويه للتخلص من هذه السموم وعلى قدر عزيمتك هيكون التوفيق لنجاح العلاج ساعد نفسك\t\"\n",
        "}\n",
        "\n",
        "example_3 = {\n",
        "    \"question\": \"اعاني من الخوف وتنبؤات من كلام اهلي وبصمتهم انهم يبون يقتلوني بدون سبب والي محرضهم ابوي\",\n",
        "    \"answer\": \"التقلبات المزاجيه في سنك المبكره كثيره ومن المفيد مراجعه طبيب للتشخيص الدقيق\t\"\n",
        "}\n",
        "\n",
        "example_4 = {\n",
        "    \"question\": \"عمرها 15 منذ قرابه شهرين او اكثر بدات حالتها تتغير من الهدوء الى العصبيه وعدم النوم\",\n",
        "    \"answer\": \"هناك العديد من الاسئله هل يوجد خلافات في المنزل هل تعرضت لاي ضغوط او اي صدمه ؟ يمكنك التواصل مباشره مع معالج نفسي للمساعده\"\n",
        "}\n",
        "\n",
        "example_5 = {\n",
        "    \"question\": \"قلق وتوتر ووسواس قهري وتاتاه في الكلام وعجز داخلي اظن اني مكروه واني لا اقدر افعل شي\t\",\n",
        "    \"answer\": \"انشغل بالدراسه اوالعمل او الانشطه الاجتماعيه ومع تلقي العلاج النفسي تتحسن الحاله مع التدريب والصبر\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpZ6a4DpBD6z"
      },
      "outputs": [],
      "source": [
        "def build_fewshot_5_prompt(new_question):\n",
        "    prompt = f\"\"\"\n",
        "أجب على الأسئلة التالية باحترافية وباللغة العربية:\n",
        "\n",
        "س: {example_1['question']}\n",
        "ج: {example_1['answer']}\n",
        "\n",
        "س: {example_2['question']}\n",
        "ج: {example_2['answer']}\n",
        "\n",
        "س: {example_3['question']}\n",
        "ج: {example_3['answer']}\n",
        "\n",
        "س: {example_4['question']}\n",
        "ج: {example_4['answer']}\n",
        "\n",
        "س: {example_5['question']}\n",
        "ج: {example_5['answer']}\n",
        "\n",
        "س: {new_question}\n",
        "ج:\"\"\"\n",
        "    return prompt.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ATufkq9BF6D"
      },
      "outputs": [],
      "source": [
        "def generate_llama_fewshot_5_answer(question):\n",
        "    prompt = build_fewshot_5_prompt(question)\n",
        "    response = chat.invoke([\n",
        "        HumanMessage(content=prompt)\n",
        "    ])\n",
        "    return response.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOgUITyiBHfZ"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_fewshot_5_answer'] = sample_df['question_clean_2'].apply(generate_llama_fewshot_5_answer)\n",
        "sample_df.to_csv(\"llama_fewshot_5_answer.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWNTH_dVBKye"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_fewshot_5_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_fewshot_5'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama_fewshot_5_answer.csv\", index=False)\n",
        "print(f\"✅ 5 - Few-Shot BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSjr2bH3Bp_4"
      },
      "outputs": [],
      "source": [
        "def build_fewshot_cot_prompt(new_question):\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "Question: I can't sleep and feel stressed all day. Do I have a mental illness?\n",
        "\n",
        "Let's analyze the condition gradually:\n",
        "1. Look at the symptoms: insomnia (inability to sleep) and constant stress.\n",
        "2. Associated with: disorders such as generalized anxiety or depression.\n",
        "3. To properly diagnose the condition: You must know a few things.\n",
        "4. To answer: Provide a professional answer that takes into account the above factors using one or more of the strategies:\n",
        "- providing information\n",
        "- Direct answers\n",
        "- Emotional support\n",
        "\n",
        "Answer: It is best to consult a psychologist to evaluate the condition. Lifestyle changes or behavioral therapy may help alleviate the symptoms.\n",
        "\n",
        "Make sure your answer is fully formatted in Arabic and specifically designed to diagnose mental health conditions\n",
        "\n",
        "Question: {new_question}\n",
        "Answer:\"\"\"\n",
        "    return prompt.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3dsvvIrB16B"
      },
      "outputs": [],
      "source": [
        "def generate_llama_fewshot_cot_answer(question):\n",
        "    prompt = build_fewshot_cot_prompt(question)\n",
        "    response = chat.invoke([\n",
        "        HumanMessage(content=prompt)\n",
        "    ])\n",
        "    return response.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPJPHyR3CBN1"
      },
      "outputs": [],
      "source": [
        "sample_df = df[['question_clean_2', 'answer_clean_2']].sample(n=10, random_state=42).copy()\n",
        "sample_df['llama_fewshot_cot_answer'] = sample_df['question_clean_2'].apply(generate_llama_fewshot_cot_answer)\n",
        "sample_df.to_csv(\"llama_fewshot_cot_answer.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATKtBQIBCJoU"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "P, R, F1 = score(\n",
        "    sample_df['llama_fewshot_cot_answer'].tolist(),\n",
        "    sample_df['answer_clean_2'].tolist(),\n",
        "    lang=\"ar\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "sample_df['bertscore_llama_fewshot_cot_answer'] = F1.tolist()\n",
        "sample_df.to_csv(\"llama_fewshot_cot_answer.csv\", index=False)\n",
        "print(f\"✅ CoT BERTScore F1: {F1.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6smlpaemKJLf"
      },
      "outputs": [],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8npfcN8YJ_79"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()  # أدخل توكن HF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "print(f\"Google Generative AI version: {genai.__version__}\")"
      ],
      "metadata": {
        "id": "9Wc2qF80rBek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import __version__ as hf_version\n",
        "print(f\"Hugging Face Hub version: {hf_version}\")"
      ],
      "metadata": {
        "id": "3tiRrF-qqDIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(f\"Python version: {sys.version}\")"
      ],
      "metadata": {
        "id": "yfZXXiUwqbGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICZWTSSDLUu6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Allam\n",
        "allam_model = AutoModelForCausalLM.from_pretrained(\"ALLaM-AI/ALLaM-7B-Instruct-preview\", torch_dtype=\"auto\", device_map=\"auto\")\n",
        "allam_tokenizer = AutoTokenizer.from_pretrained(\"ALLaM-AI/ALLaM-7B-Instruct-preview\")\n",
        "\n",
        "# Qwen\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\")\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0Sk1UiXKPYR"
      },
      "outputs": [],
      "source": [
        "# FINAL aLLAm\n",
        "def gen_hf(model, tokenizer, prompt):\n",
        "    # 1. Tokenize the prompt and move to model's device\n",
        "    toks = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 2. Generate the model output\n",
        "    out = model.generate(**toks, max_new_tokens=1024)\n",
        "\n",
        "    # 3. Decode only the generated part (exclude input prompt)\n",
        "    generated_tokens = out[0][toks[\"input_ids\"].shape[1]:]\n",
        "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4foyFyWK4x3"
      },
      "outputs": [],
      "source": [
        "# FINAL Qwen\n",
        "def gen_qwen(model, tokenizer, prompt):\n",
        "    # 1. Tokenize the prompt and move to model's device\n",
        "    toks = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 2. Generate output\n",
        "    out = model.generate(**toks, max_new_tokens=1024)\n",
        "\n",
        "    # 3. Decode only the generated part\n",
        "    generated_tokens = out[0][toks[\"input_ids\"].shape[1]:]\n",
        "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLYn5WmUKZQ7"
      },
      "outputs": [],
      "source": [
        "# FINAL Gemini\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"..\")\n",
        "gemini_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "def gen_gemini(model, prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaccnL0cKobq"
      },
      "outputs": [],
      "source": [
        "#FINAL GPT\n",
        "\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"sk-proj....\"\n",
        "openai_model = \"gpt-4o\"\n",
        "\n",
        "def gen_openai(prompt, model_name):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QobDXnp5Kbqz"
      },
      "outputs": [],
      "source": [
        "# FINAL\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from bert_score import score\n",
        "\n",
        "# Load 15 samples\n",
        "#df = pd.read_csv(\"Train_Dev.tsv\", sep=\"\\t\")\n",
        "df_sample = df[['question_clean_2', 'answer_clean_2']].dropna().sample(n=20, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Prepare all prompts\n",
        "df_sample[\"prompt\"] = df_sample[\"question_clean_2\"].apply(build_fewshot_prompt)\n",
        "\n",
        "# Initialize result containers\n",
        "results = {\n",
        "    \"allam\": [],\n",
        "    \"qwen\": [],\n",
        "    \"gpt\": [],\n",
        "    \"gemini\": []\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xKqZbY3MKWVN"
      },
      "outputs": [],
      "source": [
        "#FINAL\n",
        "\n",
        "# Allam\n",
        "for prompt in tqdm(df_sample[\"prompt\"], desc=\"Allam\"):\n",
        "    ans = gen_hf(allam_model, allam_tokenizer, prompt)\n",
        "    results[\"allam\"].append(ans)\n",
        "\n",
        "# Qwen\n",
        "for prompt in tqdm(df_sample[\"prompt\"], desc=\"Qwen\"):\n",
        "    ans = gen_qwen(qwen_model, qwen_tokenizer, prompt)\n",
        "    results[\"qwen\"].append(ans)\n",
        "\n",
        "# OpenAI GPT\n",
        "for prompt in tqdm(df_sample[\"prompt\"], desc=\"GPT\"):\n",
        "    ans = gen_openai(prompt, openai_model)\n",
        "    results[\"gpt\"].append(ans)\n",
        "\n",
        "# Gemini\n",
        "for prompt in tqdm(df_sample[\"prompt\"], desc=\"Gemini\"):\n",
        "    ans = gen_gemini(gemini_model, prompt)\n",
        "    results[\"gemini\"].append(ans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ruc7cPq9XDz_"
      },
      "outputs": [],
      "source": [
        "bert_results = {}\n",
        "\n",
        "for model_name in results.keys():\n",
        "    print(f\"Scoring {model_name}...\")\n",
        "    P, R, F1 = score(\n",
        "        results[model_name],\n",
        "        df_sample[\"answer_clean_2\"].tolist(),\n",
        "        lang=\"ar\",\n",
        "        verbose=True\n",
        "    )\n",
        "    bert_results[model_name] = {\n",
        "        \"precision\": P.mean().item(),\n",
        "        \"recall\": R.mean().item(),\n",
        "        \"f1\": F1.mean().item()\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2j9oNRMY-Em"
      },
      "outputs": [],
      "source": [
        "print(\"\\n📊 Final Average BERTScore F1 per Model:\")\n",
        "for model_name, scores in bert_results.items():\n",
        "    print(f\"{model_name}: F1 = {scores['f1']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
